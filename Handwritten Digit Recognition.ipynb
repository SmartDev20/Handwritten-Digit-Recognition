{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c26bfe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , Flatten\n",
    "from keras.layers import Conv2D , MaxPool2D\n",
    "from keras import backend as k\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d904745c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "(10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train , y_train) , (x_test , y_test) = mnist.load_data()\n",
    "print(x_train.shape , y_train.shape)\n",
    "print(x_test.shape , y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0dce02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff7bec720d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bfdff9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ed31982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff7bec3ba60>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32a0eaf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7c7c5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0] , 28 , 28 , 1)\n",
    "x_test = x_test.reshape(x_test.shape[0] , 28 , 28 , 1)\n",
    "\n",
    "input_shape = (28 , 28 , 1)\n",
    "num_classes = 10\n",
    "\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train , num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test , num_classes)\n",
    "\n",
    "\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90680d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-06 18:35:48.345515: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-10-06 18:35:48.345566: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-10-06 18:35:48.345595: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ews): /proc/driver/nvidia/version does not exist\n",
      "2021-10-06 18:35:48.345886: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-06 18:35:48.700864: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 97s 204ms/step - loss: 2.2676 - accuracy: 0.1695 - val_loss: 2.2215 - val_accuracy: 0.4258\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 100s 214ms/step - loss: 2.1896 - accuracy: 0.3105 - val_loss: 2.1205 - val_accuracy: 0.5952\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 103s 219ms/step - loss: 2.0797 - accuracy: 0.4326 - val_loss: 1.9753 - val_accuracy: 0.6894\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 98s 210ms/step - loss: 1.9214 - accuracy: 0.5363 - val_loss: 1.7705 - val_accuracy: 0.7489\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 103s 220ms/step - loss: 1.7184 - accuracy: 0.6072 - val_loss: 1.5167 - val_accuracy: 0.7858\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 106s 226ms/step - loss: 1.4852 - accuracy: 0.6558 - val_loss: 1.2510 - val_accuracy: 0.8093\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 106s 225ms/step - loss: 1.2667 - accuracy: 0.6907 - val_loss: 1.0211 - val_accuracy: 0.8252\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 102s 217ms/step - loss: 1.0954 - accuracy: 0.7141 - val_loss: 0.8532 - val_accuracy: 0.8370\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 103s 220ms/step - loss: 0.9649 - accuracy: 0.7344 - val_loss: 0.7353 - val_accuracy: 0.8446\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 103s 220ms/step - loss: 0.8724 - accuracy: 0.7513 - val_loss: 0.6516 - val_accuracy: 0.8540\n",
      "The model has successfully trained\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32 , kernel_size=(3,3) , activation='relu' , input_shape=input_shape))\n",
    "model.add(Conv2D(64 , (3,3) , activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256 , activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes , activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "\n",
    "print(\"The model has successfully trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f768fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.6516439914703369\n",
      "Test accuracy: 0.8539999723434448\n",
      "Saving the model as DigitModel.h5\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "model.save('DigitModel.h5')\n",
    "print(\"Saving the model as DigitModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef536f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/tkinter/__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/tmp/ipykernel_6177/561267856.py\", line 67, in show_image\n",
      "    messagebox.info(\"\" , \"hiiiiiii\")\n",
      "AttributeError: module 'tkinter.messagebox' has no attribute 'info'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/tkinter/__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/tmp/ipykernel_6177/561267856.py\", line 67, in show_image\n",
      "    messagebox.info(\"\" , \"hiiiiiii\")\n",
      "AttributeError: module 'tkinter.messagebox' has no attribute 'info'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/tkinter/__init__.py\", line 1892, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/tmp/ipykernel_6177/561267856.py\", line 67, in show_image\n",
      "    messagebox.info(\"\" , \"hiiiiiii\")\n",
      "AttributeError: module 'tkinter.messagebox' has no attribute 'info'\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from PIL import Image ,  ImageTk\n",
    "import numpy as np\n",
    "import easygui as eg\n",
    "\n",
    "\n",
    "\n",
    "model = load_model('DigitModel.h5')\n",
    "\n",
    "def predict_image(img) :\n",
    "    img = img.resize((28 , 28))\n",
    "    #convert rgb to grayscale\n",
    "    img = img.convert('L')\n",
    "    img = np.array(img)\n",
    "    #reshaping to support our model input and normalizing\n",
    "    img = img.reshape(1 , 28 , 28 , 1)\n",
    "    img = img / 255.0\n",
    "    #predicting the class of image\n",
    "    res = model.predict([img])[0]\n",
    "    return (np.argmax(res) , max(res))\n",
    "\n",
    "\n",
    "class App(tk.Tk) :\n",
    "    def __init__(self) :\n",
    "        tk.Tk.__init__(self)\n",
    "        self.x = self.y = 0\n",
    "        \n",
    "        \n",
    "        # Creating elements\n",
    "        #self.canvas = tk.Canvas(self , width = 600 , height = 600 , bg = 'white' , cursor = 'cross')\n",
    "        self.label = tk.Label(self , text = 'Prediction' , font = (\"Helvetica\", 25))\n",
    "        self.select_btn = tk.Button(self , text = \"Select\", command = self.select_image)\n",
    "        self.clear_btn = tk.Button(self , text = 'Clear' , command = self.clear_all)\n",
    "        self.show_btn = tk.Button(self , text = 'Show' , command = self.show_image)\n",
    "        self.classify_btn = tk.Button(self , text = 'Recognize' , command = self.classify_image)\n",
    "        #self.path_label = tk.Label(self , text = 'Your Image Path' , font = (\"Helvetica\", 10))\n",
    "        self.path_label = tk.Label(self , width = 100 , height = 20 , bg = 'white' , cursor = 'cross')\n",
    "        \n",
    "        # Grid structure\n",
    "        #self.canvas.grid(row = 0 , column = 0 , pady = 2 , sticky= W)\n",
    "        self.label.grid(row = 0 , column = 1 , pady = 2 , padx = 2)\n",
    "        self.path_label.grid(row = 0 , column = 0 , pady = 2 , padx = 2)\n",
    "        self.classify_btn.grid(row = 2 , column = 2 , pady = 2 , padx = 2)\n",
    "        self.select_btn.grid(row = 2 , column = 0 , pady = 2 , padx = 2)\n",
    "        self.show_btn.grid(row = 2 , column = 1 , pady = 2 , padx = 2)\n",
    "        self.clear_btn.grid(row = 2 , column = 3 , pady = 2 , padx = 2)\n",
    "        \n",
    "    def clear_all(self) :\n",
    "        #self.canvas.delete('all')\n",
    "        self.label.configure(text = '')\n",
    "        self.path_label.configure(text = '')\n",
    "        \n",
    "    def select_image(self) :\n",
    "        img_path = eg.fileopenbox()\n",
    "        self.path_label.configure(text = img_path)\n",
    "        \n",
    "    def show_image(self) :\n",
    "        img_path = self.path_label['text']\n",
    "        img = ImageTk.PhotoImage(Image.open(img_path)) \n",
    "        img=Image.open(img_path)\n",
    "        img = img.resize((300, 300), Image.ANTIALIAS)\n",
    "        test = ImageTk.PhotoImage(img)\n",
    "        #self.canvas.create_image(10 , 10 , anchor = NW , image = img )\n",
    "        self.path_label.configure(image = test)\n",
    "        messagebox.INFO(\"\" , \"hiiiiiii\")\n",
    "    \n",
    "\n",
    "    def classify_image(self) :\n",
    "        img_path = self.path_label['text']\n",
    "        img=Image.open(img_path)\n",
    "        dig , acc = predict_image(img)\n",
    "        self.label.configure(text = str(dig) + ' : ' + str(int(acc*100)) + '%')\n",
    "        \n",
    "app = App()\n",
    "app.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad76032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c133ef1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TclError",
     "evalue": "image \"pyimage3\" doesn't exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14828/2151138549.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageTk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPhotoImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/nabih/Handwritten-Digit-Recognition/3.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0manchor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNW\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tkinter/__init__.py\u001b[0m in \u001b[0;36mcreate_image\u001b[0;34m(self, *args, **kw)\u001b[0m\n\u001b[1;32m   2788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m         \u001b[0;34m\"\"\"Create image item with coordinates x1,y1.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/tkinter/__init__.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(self, itemType, args, kw)\u001b[0m\n\u001b[1;32m   2774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2775\u001b[0m             \u001b[0mcnf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2776\u001b[0;31m         return self.tk.getint(self.tk.call(\n\u001b[0m\u001b[1;32m   2777\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'create'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitemType\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2778\u001b[0m             *(args + self._options(cnf, kw))))\n",
      "\u001b[0;31mTclError\u001b[0m: image \"pyimage3\" doesn't exist"
     ]
    }
   ],
   "source": [
    "from tkinter import *  \n",
    "from PIL import ImageTk,Image  \n",
    "\n",
    "ws = Tk()  \n",
    "ws.title('Photo')\n",
    "#ws.geometry('500x500')\n",
    "\n",
    "def classify_handwriting() :\n",
    "        img_path = eg.fileopenbox()\n",
    "        messagebox.showinfo(title='Path' , message=img_path)\n",
    "        img=Image.open(img_path)\n",
    "        img = ImageTk.PhotoImage(img) \n",
    "       # canvas.create_image(10 , 10 , anchor = NW , image = img ) \n",
    "\n",
    "canvas = Canvas( ws, width = 500, height = 500 , bg = 'white' )  \n",
    "canvas.grid(row = 0 , column = 0 , pady = 2 , padx = 2)  \n",
    "classify_btn = Button(ws , text = \"Recognise\", command = classify_handwriting)\n",
    "classify_btn.grid(row = 1 , column = 0 , pady = 2 , padx = 2) \n",
    "\n",
    "\n",
    "\n",
    "img = ImageTk.PhotoImage(Image.open('/home/nabih/Handwritten-Digit-Recognition/3.jpg')) \n",
    "canvas.create_image(10 , 10 , anchor = NW , image =  img)\n",
    "\n",
    "     \n",
    "ws.mainloop() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c399d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
